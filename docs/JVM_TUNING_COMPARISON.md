# JVM 튜닝 전후 비교

## 1. 배경

- **기준선**: G1GC + Non-Heap 제한(메타스페이스 256MB, Code Cache 128MB, Direct Memory 64MB, Thread Stack 512KB)
- **측정 방식**: JMH 벤치마크 (warmup 1회, measurement 2회)
- **주요 지표**: TPS (μs/op 역수), GC pause(평균/최대), GC 횟수

## 2. Non-Heap 제한 추가 결과 (비교 기준)

- **비포**: 제한 없이 TPS 2,322(~ limitOrder @1k) / 평균 pause 1.4ms / 최대 5.5ms
- **애프터**: Non-Heap 제한 적용 → TPS 2,517 / 평균 pause 1.8ms / 최대 2.6ms
- **개선 포인트**:
  - 최대 pause가 절반으로 줄어 예측 가능성 증가
  - 소규모 TPS +8%
  - Direct/Metaspace 범위 명시 → OOM 리스크 감소

## 3. 옵션별 TPS 정리

| 옵션                              | limitOrder@1k TPS | marketBuy@1k TPS | mixed@1k TPS | comment                                        |
| --------------------------------- | ----------------- | ---------------- | ------------ | ---------------------------------------------- |
| 기준 (G1 + Non-Heap 제한)         | 2,493             | 1,822            | 1,853        | 현재 기준                                      |
| ZGC                               | 2,327             | 1,906            | 1,848        | latency 최우선, assembly-level pause 거의 없음 |
| MaxGCPauseMillis=100              | 2,303             | 1,910            | 2,012        | G1 유지하며 pause 제한                         |
| InitiatingHeapOccupancyPercent=35 | 2,309             | 1,847            | 1,870        | GC 타이밍 앞당겨 pause 간격 짧음               |

%로 보면 기준 대비 ZGC -7%/ +4%/0%, MaxPauseMillis -8%/+4%/+9%, InitiatingHeapOcc -7%/+1%/+1%로, ZGC만 latency trade-off를 감수하고 TPS가 조금 내려가는 반면 다른 옵션은 거의 동일하거나 약간 개선되는 것을 보여줍니다.

## 3. JVM 옵션 스윕 비교

| 옵션                                    | GC 유형 | pause (avg) | pause (max) | TPS trend (limitOrder@1k) | 메모                                     | GC count                |
| --------------------------------------- | ------- | ----------- | ----------- | ------------------------- | ---------------------------------------- | ----------------------- |
| 기준 (G1 + Non-Heap 제한)               | G1GC    | ~1.8ms      | ~2.64ms     | 401us/op (~2,493 TPS)     | 최대 pause 감소                          | ~20                     |
| ZGC (`-XX:+UseZGC`)                     | ZGC     | ~0.003ms    | ~0.006ms    | 430us/op (~2,327 TPS)     | latency 극소화, throughput 약간 감소     | 60 (young과 concurrent) |
| `-XX:MaxGCPauseMillis=100`              | G1GC    | ~1.71ms     | ~3.24ms     | 434us/op (~2,303 TPS)     | pause 제한 & G1 유지                     | 19                      |
| `-XX:InitiatingHeapOccupancyPercent=35` | G1GC    | ~1.85ms     | ~4.89ms     | 433us/op (~2,309 TPS)     | GC 타이밍 앞당김, 더 규칙적인 짧은 pause | 20                      |

## 4. 정리

1.  Non-Heap 제한 + G1GC 기준으로 안정성과 최대 pause 개선이 가장 명확하므로 기본값으로 유지
2.  ZGC는 pause가 거의 0에 가까워지지만 throughput은 살짝 떨어짐 → latency 최우선 워크로드에서 고려
3.  `MaxGCPauseMillis` / `InitiatingHeapOccupancyPercent` 조합으로 G1 특성을 유지하며 pause를 다듬을 수 있음을 확인
4.  향후 코드 최적화(객체 풀링 등) 후 동일한 표 형식으로 비교하면, JVM 조정과 코드 변경의 효과를 분리해 측정 가능

## 4-1. 왜 TPS 상승이 크지 않았나?

1. **메모리 할당이 병목**: TPS는 단순히 GC가 아니라 주문마다 새 객체를 만드는 시간, BigDecimal 연산, HashMap/TreeMap 탐색 등 여러 작업이 걸려서 조정 가능한 메모리 옵션만으로는 큰 변화가 어렵습니다.
2. **대부분 짧은 pause**: G1GC와 ZGC 모두 이미 pause가 짧은 편이어서 또 짧게 만들어도 체감 성능이 거의 변하지 않음. 그래서 TPS 숫자는 조금만 들쑤시거나 측정 오차 범위에 들 수도 있습니다.
3. **벤치마크 워크로드의 특성**: 모든 옵션에서 주문 생성 자체의 오버헤드가 동일하므로 GC 설정을 바꾼다고 엄청난 TPS 증가가 나오기보다는 ‘조금씩’ 개선되는 경향이 나타납니다.

> 요약: JVM 옵션만으로 TPS를 올리려면 병목이 GC로 명확히 드러날 때로 한정됩니다. 지금은 주문 처리 논리 쪽도 함께 손봐야 큰 CPS 개선이 보일 수 있다는 뜻입니다.

## 5. 다음 단계 제안

1. 현재 벤치마크 결과를 기준으로 코드 최적화 후 TPS 및 GC 로그를 추가 측정
2. ZGC 또는 G1 pause 목표를 실제 서비스 workload (예: 재현 스크립트)로 검증
3. 본 문서에 코드 변경 전/후도 같은 형식으로 추가 (객체 풀링 적용 등)

## 6. 전체 튜닝 과정 비교 (3단계)

### 6.1. 비교 개요

튜닝 과정을 3단계로 나누어 비교합니다:

1. **초기 상태**: JVM 튜닝 없음, 코드 최적화 없음 (원래 코드 그대로)
2. **JVM만 튜닝 후**: Non-Heap 제한 + 여러 JVM 옵션 튜닝 시도 (ZGC, MaxGCPauseMillis, InitiatingHeapOccupancyPercent 등)
   - 여러 옵션을 시도한 결과, **Non-Heap 제한이 가장 좋은 성능을 보였음** (이 값을 대표값으로 사용)
3. **JVM 튜닝 + 코드 최적화 후**: JVM 튜닝(2단계 결과) + 벤치마크 코드 최적화 (BigDecimal 캐싱)

### 6.2. TPS 비교 (주문 수 1,000 기준)

| 지표            | 초기 상태 | JVM만 튜닝 후   | JVM+코드 최적화 후 | JVM 튜닝 효과 | 코드 최적화 효과 |
| --------------- | --------- | --------------- | ------------------ | ------------- | ---------------- |
| limitOrderTps   | 2,322 TPS | 2,517 TPS       | 2,417 TPS          | +8.4% ⬆️      | -4.0% ⬇️         |
| (430.661 μs/op) |           | (397.344 μs/op) | (413.784 μs/op)    |               |                  |
| marketBuyTps    | 1,929 TPS | 1,918 TPS       | 1,813 TPS          | -0.6%         | -5.5% ⬇️         |
| (518.299 μs/op) |           | (521.474 μs/op) | (551.548 μs/op)    |               |                  |
| mixedTps        | 1,943 TPS | 1,947 TPS       | 2,000 TPS          | +0.2%         | +2.7% ⬆️         |
| (514.667 μs/op) |           | (513.518 μs/op) | (499.946 μs/op)    |               |                  |

**주요 관찰:**

- **JVM 튜닝 효과**: limitOrderTps에서 8.4% 향상 (가장 큰 개선)
- **코드 최적화 효과**: mixedTps에서 2.7% 향상, 다른 항목은 약간 저하 (측정 오차 범위)
- **전체적으로**: 초기 대비 limitOrderTps는 +4.1% 향상, mixedTps는 +2.9% 향상

### 6.3. GC 통계 비교

| 항목            | 초기 상태 | JVM만 튜닝 후 | JVM+코드 최적화 후 | 변화 요약                              |
| --------------- | --------- | ------------- | ------------------ | -------------------------------------- |
| 평균 pause time | 1.4ms     | 1.8ms         | 1.81ms             | 약간 증가하지만 최대값 개선으로 안정적 |
| 최대 pause time | 5.5ms     | 2.6ms         | 2.64ms             | **53% 개선!** ⬇️                       |
| GC 빈도         | 20회/분   | 20회/분       | 20회/분            | 동일                                   |

**GC 관찰:**

- **최대 pause time**: 5.5ms → 2.6ms로 크게 개선 (예측 가능성 향상)
- **평균 pause time**: 약간 증가했지만 최대값이 크게 줄어서 전체적으로 안정적
- **GC 빈도**: 변화 없음 (코드 최적화로도 GC 빈도는 크게 변하지 않음)

### 6.4. 코드 최적화 내용

#### 변경한 내용

- `buildLimitOrder`/`buildMarketBuyOrder` 반복적으로 새로 생성하던 `BigDecimal` 인스턴스를 상수 및 테이블로 캐싱
- 금액/가격 계산을 static array(LIMIT_PRICE_TABLE, MIXED_PRICE_TABLE)에서 조회하도록 변경해서 GC 압력을 낮추는 목적
- 주문당 `new BigDecimal("1.0")`, `BigDecimal("100.00")` 등을 제거하고 재사용 가능한 객체만 사용

### 6.5. 왜 큰 TPS 증가는 나오지 않았나?

#### JVM 튜닝만으로는

1. **메모리 할당이 병목**: TPS는 단순히 GC가 아니라 주문마다 새 객체를 만드는 시간, BigDecimal 연산, HashMap/TreeMap 탐색 등 여러 작업이 걸려서 조정 가능한 메모리 옵션만으로는 큰 변화가 어렵습니다.
2. **대부분 짧은 pause**: G1GC는 이미 pause가 짧은 편이어서 또 짧게 만들어도 체감 성능이 거의 변하지 않습니다. 그래서 TPS 숫자는 조금만 들쑤시거나 측정 오차 범위에 들 수도 있습니다.
3. **벤치마크 워크로드의 특성**: 모든 옵션에서 주문 생성 자체의 오버헤드가 동일하므로 GC 설정을 바꾼다고 엄청난 TPS 증가가 나오기보다는 '조금씩' 개선되는 경향이 나타납니다.

#### 코드 최적화로도

1. **코드 오버헤드가 더 뚜렷**: 오더 생성/매칭 자체가 여전히 가장 많은 시간을 쓰기 때문에, BigDecimal 캐싱만으로 전체 TPS가 크게 올라가지 않음
2. **측정 오차 범위**: Warmup·measurement 설정이 짧아 ±5% 수준의 오차가 존재 → 변화폭이 그 안에 있음
3. **GC보단 주문 논리**: GC pause는 거의 변하지 않았고, CPU가 주문 생성·매칭에 쓰이므로 메모리 객체 재사용 효과가 전체 TPS로 연결되기 어려움

> **결론**: JVM 튜닝으로 최대 pause time을 크게 개선했고, 일부 TPS도 향상되었습니다. 하지만 코드 최적화(BigDecimal 캐싱)만으로는 큰 성능 향상을 기대하기 어려웠습니다. 다음에는 실제 엔진 코드(객체 풀링, 매칭 루프 개선 등)를 최적화하면 더 눈에 띄는 성능 향상이 기대됩니다.
